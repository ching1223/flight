{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料合併-短程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/tokyo.csv\n",
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/tokyo_business.csv\n",
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/hongkong.csv\n",
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/hongkong_business.csv\n",
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/singapore.csv\n",
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/singapore_business.csv\n",
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/bangkok.csv\n",
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/seoul.csv\n",
      "正在讀取檔案：/Users/yuchingchen/Documents/專題/cleaned_data/data/short/seoul_business.csv\n",
      "合併完成，結果儲存至：/Users/yuchingchen/Documents/專題/cleaned_data/short_flight.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def merge_files(file_paths, output_path):\n",
    "    data_frames = []\n",
    "    \n",
    "    # 逐一讀取檔案\n",
    "    for file_path in file_paths:\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"正在讀取檔案：{file_path}\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            if not df.empty:\n",
    "                data_frames.append(df)\n",
    "            else:\n",
    "                print(f\"檔案 {file_path} 為空，跳過。\")\n",
    "        else:\n",
    "            print(f\"檔案 {file_path} 不存在，跳過。\")\n",
    "\n",
    "    # 合併所有資料\n",
    "    if data_frames:\n",
    "        merged_data = pd.concat(data_frames, ignore_index=True)\n",
    "        merged_data.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"合併完成，結果儲存至：{output_path}\")\n",
    "    else:\n",
    "        print(\"沒有任何資料可供合併。\")\n",
    "\n",
    "# 主程式\n",
    "base_path = '/Users/yuchingchen/Documents/專題/cleaned_data/data/short'\n",
    "output_path = '/Users/yuchingchen/Documents/專題/cleaned_data/short_flight.csv'\n",
    "\n",
    "# 檔案名稱清單\n",
    "file_paths = [\n",
    "    f'{base_path}/tokyo.csv',\n",
    "    f'{base_path}/tokyo_business.csv',\n",
    "    f'{base_path}/hongkong.csv',\n",
    "    f'{base_path}/hongkong_business.csv',\n",
    "    f'{base_path}/singapore.csv',\n",
    "    f'{base_path}/singapore_business.csv',\n",
    "    f'{base_path}/bangkok.csv',\n",
    "    f'{base_path}/seoul.csv',\n",
    "    f'{base_path}/seoul_business.csv'\n",
    "]\n",
    "\n",
    "# 合併檔案\n",
    "merge_files(file_paths, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 短程 機場資料 ===\n",
      "   Airport  Passengers  Movements\n",
      "0  日本羽田HND    78719302     464910\n",
      "1    仁川ICN    71169722     337299\n",
      "2   新加坡SIN    58946000     328000\n",
      "3    泰國BKK    51699104     294085\n",
      "4    香港HKG    39452633     276000\n",
      "5  日本成田NRT    32705995     209927\n",
      "6    金浦GMP    21566946     134560\n",
      "\n",
      "短程：加入 PCA 後的資料\n",
      "   Airport  Passengers  Movements       PC1       PC2\n",
      "0  日本羽田HND    78719302     464910  2.304679  0.230734\n",
      "1    仁川ICN    71169722     337299  1.089987 -0.426968\n",
      "2   新加坡SIN    58946000     328000  0.570849 -0.044270\n",
      "3    泰國BKK    51699104     294085  0.054708 -0.025752\n",
      "4    香港HKG    39452633     276000 -0.529727  0.293328\n",
      "5  日本成田NRT    32705995     209927 -1.263336  0.057469\n",
      "6    金浦GMP    21566946     134560 -2.227159 -0.084542\n",
      "\n",
      "短程：最終資料（含 PC1, PC2, 與兩種分類方式）\n",
      "   Airport  Passengers  Movements       PC1       PC2 Classification_PC1  \\\n",
      "0  日本羽田HND    78719302     464910  2.304679  0.230734               大型機場   \n",
      "1    仁川ICN    71169722     337299  1.089987 -0.426968               大型機場   \n",
      "2   新加坡SIN    58946000     328000  0.570849 -0.044270               中型機場   \n",
      "3    泰國BKK    51699104     294085  0.054708 -0.025752               中型機場   \n",
      "4    香港HKG    39452633     276000 -0.529727  0.293328               小型機場   \n",
      "5  日本成田NRT    32705995     209927 -1.263336  0.057469               小型機場   \n",
      "6    金浦GMP    21566946     134560 -2.227159 -0.084542               小型機場   \n",
      "\n",
      "  Cluster_Label  \n",
      "0     Cluster C  \n",
      "1     Cluster A  \n",
      "2     Cluster A  \n",
      "3     Cluster A  \n",
      "4     Cluster A  \n",
      "5     Cluster B  \n",
      "6     Cluster B  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# 1. 資料\n",
    "#-------------------------------------------------------------\n",
    "# 以下為範例資料，請依實際狀況調整\n",
    "data_short = {\n",
    "    'Airport': ['日本羽田HND', '仁川ICN', '新加坡SIN', '泰國BKK', '香港HKG', '日本成田NRT', '金浦GMP'],\n",
    "    'Passengers': [78719302, 71169722, 58946000, 51699104, 39452633, 32705995, 21566946],  # 範例數字\n",
    "    'Movements': [464910, 337299, 328000, 294085, 276000, 209927, 134560]              # 範例數字\n",
    "}\n",
    "\n",
    "df_short = pd.DataFrame(data_short)\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# 2. 封裝一個函式，方便對「長程」或「短程」資料重複執行\n",
    "#-------------------------------------------------------------\n",
    "def analyze_airports(df, group_name):\n",
    "    print(f\"\\n=== {group_name} 機場資料 ===\")\n",
    "    print(df)\n",
    "\n",
    "    # 2.1 特徵欄位\n",
    "    features = ['Passengers', 'Movements']\n",
    "    X = df[features].values\n",
    "    \n",
    "    # 2.2 標準化\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    \n",
    "    # 2.3 PCA（此處 n_components=2）\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_std)\n",
    "    \n",
    "    df['PC1'] = X_pca[:, 0]\n",
    "    df['PC2'] = X_pca[:, 1]\n",
    "    \n",
    "    print(f\"\\n{group_name}：加入 PCA 後的資料\")\n",
    "    print(df)\n",
    "    \n",
    "    # 2.4 以 PC1 做簡易分類\n",
    "    def classify_by_pc1(pc1):\n",
    "        if pc1 > 1:\n",
    "            return '大型機場'\n",
    "        elif pc1 > 0:\n",
    "            return '中型機場'\n",
    "        else:\n",
    "            return '小型機場'\n",
    "    \n",
    "    df['Classification_PC1'] = df['PC1'].apply(classify_by_pc1)\n",
    "    \n",
    "    # 2.5 K-means 分群 (三群為例)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    df['Cluster'] = kmeans.fit_predict(X_pca)\n",
    "    \n",
    "    # 命名分群結果（可根據實際觀察再重新命名）\n",
    "    cluster_map = {\n",
    "        0: 'Cluster A',\n",
    "        1: 'Cluster B',\n",
    "        2: 'Cluster C'\n",
    "    }\n",
    "    df['Cluster_Label'] = df['Cluster'].map(cluster_map)\n",
    "    \n",
    "    print(f\"\\n{group_name}：最終資料（含 PC1, PC2, 與兩種分類方式）\")\n",
    "    print(df[['Airport', 'Passengers', 'Movements', 'PC1', 'PC2', \n",
    "              'Classification_PC1', 'Cluster_Label']])\n",
    "    \n",
    "    # 回傳結果 DataFrame（若後續要做更多分析，可再利用）\n",
    "    return df\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# 3. 對短程做分析\n",
    "#-------------------------------------------------------------\n",
    "df_short_result = analyze_airports(df_short, \"短程\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 短程航班"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抵達機場代號\n",
      "HKG    3586\n",
      "NRT    1985\n",
      "BKK    1695\n",
      "ICN    1233\n",
      "SIN    1053\n",
      "HND    1018\n",
      "GMP     174\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'國家'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ty/th__2_pn1js9hzn2y7l830wr0000gn/T/ipykernel_25943/3453369165.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0mcountry_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"上界\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountry_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcountry_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0mcountry_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"下界\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountry_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcountry_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;31m# 合併計算結果到原始數據\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"上界\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"下界\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"國家\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;31m# 移除超出範圍的異常值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0mfiltered_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"平均價格_log\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"下界\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"平均價格_log\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"上界\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10829\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '國家'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --------------------------\n",
    "# 1. 載入資料及初步處理\n",
    "# --------------------------\n",
    "data_path = '/Users/yuchingchen/Documents/專題/cleaned_data/short_flight.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# 統一「出發日期」格式為 \"YYYY-MM-DD\"\n",
    "data[\"出發日期\"] = pd.to_datetime(\n",
    "    data[\"出發日期\"], \n",
    "    format=\"%Y-%m-%d\", \n",
    "    errors=\"coerce\"\n",
    ").combine_first(\n",
    "    pd.to_datetime(data[\"出發日期\"], format=\"%Y/%m/%d\", errors=\"coerce\")\n",
    ")\n",
    "data[\"出發日期\"] = data[\"出發日期\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# --------------------------\n",
    "# 2. 計算對數變數與新增最低價格天數\n",
    "# --------------------------\n",
    "data[\"平均價格_log\"] = data[\"平均價格\"].apply(lambda x: np.log1p(x) if pd.notnull(x) else np.nan).round(2)\n",
    "data[\"最低價格_log\"] = data[\"最低價格\"].apply(lambda x: np.log1p(x) if pd.notnull(x) else np.nan).round(2)\n",
    "data[\"價格變異_log\"] = data[\"價格變異\"].apply(lambda x: np.log1p(x) if pd.notnull(x) else np.nan).round(2)\n",
    "data[\"中位數價格_log\"] = data[\"中位數價格\"].apply(lambda x: np.log1p(x) if pd.notnull(x) else np.nan).round(2)\n",
    "\n",
    "# 新增最低價格天數 (91 - '最低價格剩餘天數')\n",
    "data['最低價格天數'] = 91 - data['最低價格剩餘天數']\n",
    "\n",
    "# 移除包含 NaN 的數據（針對關鍵欄位）\n",
    "data = data.dropna(subset=[\"平均價格_log\", \"最低價格_log\", \"最低價格天數\", \"價格變異_log\", \"中位數價格_log\"])\n",
    "\n",
    "# 顯示抵達機場代號種類及數量\n",
    "print(data['抵達機場代號'].value_counts())\n",
    "\n",
    "# --------------------------\n",
    "# 3. 假期判斷\n",
    "# --------------------------\n",
    "holidays = {\n",
    "    \"台灣\": [(\"2025-01-20\", \"2025-02-02\"), (\"2025-02-28\", \"2025-03-02\")],\n",
    "    \"日本\": [(\"2025-02-11\", \"2025-02-11\"), (\"2025-02-22\", \"2025-02-24\"), (\"2025-03-20\", \"2025-03-20\")],\n",
    "    \"香港\": [(\"2025-01-29\", \"2025-01-31\")],\n",
    "    \"新加坡\": [(\"2025-01-29\", \"2025-01-30\")],\n",
    "    \"韓國\": [(\"2025-01-28\", \"2025-01-30\"), (\"2025-03-01\", \"2025-03-03\")]\n",
    "}\n",
    "\n",
    "airport_to_region = {\n",
    "    \"HKG\": \"香港\",\n",
    "    \"NRT\": \"日本\",\n",
    "    \"HND\": \"日本\",\n",
    "    \"BKK\": \"泰國\",  # 泰國沒有假期，不處理\n",
    "    \"ICN\": \"韓國\",\n",
    "    \"GMP\": \"韓國\",\n",
    "    \"SIN\": \"新加坡\"\n",
    "}\n",
    "\n",
    "# 將「出發日期」轉回 datetime 格式以利比較\n",
    "data[\"出發日期\"] = pd.to_datetime(data[\"出發日期\"])\n",
    "\n",
    "def is_holiday(row):\n",
    "    # 台灣假期判斷（以出發地為台灣）\n",
    "    for start, end in holidays[\"台灣\"]:\n",
    "        if pd.to_datetime(start) <= row[\"出發日期\"] <= pd.to_datetime(end):\n",
    "            return 1\n",
    "    # 根據抵達機場對應地區判斷假期\n",
    "    region = airport_to_region.get(row[\"抵達機場代號\"])\n",
    "    if region and region in holidays:\n",
    "        for start, end in holidays[region]:\n",
    "            if pd.to_datetime(start) <= row[\"出發日期\"] <= pd.to_datetime(end):\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "data[\"假期\"] = data.apply(is_holiday, axis=1)\n",
    "\n",
    "# 將「假期」欄位移至「艙等」欄位之後（若「艙等」存在）\n",
    "cols = data.columns.tolist()\n",
    "if '假期' in cols and '艙等' in cols:\n",
    "    cols.insert(cols.index('艙等') + 1, cols.pop(cols.index('假期')))\n",
    "data = data[cols]\n",
    "\n",
    "# --------------------------\n",
    "# 4. 新增額外的地區經濟資料\n",
    "# --------------------------\n",
    "additional_data = {\n",
    "    \"Region\": [\"香港\", \"日本\", \"新加坡\", \"韓國\", \"泰國\"],\n",
    "    \"Cost of Living Index\": [70.8, 46.1, 76.7, 60.1, 34.1],\n",
    "    \"GDP (PPP) per capita (in thousand USD)\": [71.627, 51.399, 141.553, 60.046, 23.981],\n",
    "    \"經濟指標\": [0.6313249, -0.84717, 2.1585612, -0.059982, -1.882734]\n",
    "}\n",
    "region_df = pd.DataFrame(additional_data)\n",
    "\n",
    "data[\"Region\"] = data[\"抵達機場代號\"].map(airport_to_region)\n",
    "data = data.merge(region_df, how=\"left\", on=\"Region\")\n",
    "\n",
    "# --------------------------\n",
    "# 5. 新增是否為平日欄位\n",
    "# --------------------------\n",
    "weekend_days = [\"週六\", \"週日\"]\n",
    "data[\"是否為平日\"] = data[\"星期\"].apply(lambda x: 1 if x in weekend_days else 0)\n",
    "\n",
    "# 將「是否為平日」欄位移至「是否過夜」欄位之後\n",
    "cols = data.columns.tolist()\n",
    "if '是否過夜' in cols and '是否為平日' in cols:\n",
    "    idx = cols.index(\"是否過夜\") + 1\n",
    "    cols.insert(idx, cols.pop(cols.index(\"是否為平日\")))\n",
    "data = data[cols]\n",
    "\n",
    "# --------------------------\n",
    "# 6. 新增機場分類欄位\n",
    "# --------------------------\n",
    "super_large_airports = ['HND', 'ICN']\n",
    "largr_airports = ['SIN', 'BKK']\n",
    "medium_large_airports = ['HKG', 'GMP', 'NRT']\n",
    "\n",
    "data['機場分類'] = data['抵達機場代號'].apply(\n",
    "    lambda x: 1 if x in super_large_airports else (2 if x in medium_large_airports else None)\n",
    ").astype('Int64')\n",
    "\n",
    "# 將「機場客運量分類」移至「抵達機場代號」後\n",
    "cols = data.columns.tolist()\n",
    "if '抵達機場代號' in cols and '機場分類' in cols:\n",
    "    arrival_idx = cols.index('抵達機場代號')\n",
    "    cols.insert(arrival_idx + 1, cols.pop(cols.index('機場分類')))\n",
    "data = data[cols]\n",
    "\n",
    "# --------------------------\n",
    "# 7. 新增機場指標欄位\n",
    "# --------------------------\n",
    "airport_index = {\n",
    "    \"HND\": 0.7560275,\n",
    "    \"ICN\": 1.5913391,\n",
    "    \"SIN\": 1.0416285,\n",
    "    \"BKK\": 0.4139873,\n",
    "    \"HKG\": -0.229905,\n",
    "    \"NRT\": -1.180738,\n",
    "    \"GMP\": -2.39234\n",
    "}\n",
    "\n",
    "# 新增「機場指標」欄位\n",
    "data['機場指標'] = data['抵達機場代號'].map(airport_index)\n",
    "\n",
    "# 將「機場指標」移至「經濟指標」欄位之後\n",
    "cols = data.columns.tolist()\n",
    "if '經濟指標' in cols and '機場指標' in cols:\n",
    "    flight_idx = cols.index('經濟指標')\n",
    "    cols.insert(flight_idx + 1, cols.pop(cols.index('機場指標')))\n",
    "data = data[cols]\n",
    "\n",
    "# --------------------------\n",
    "# 8. 新增「飛行時間_分鐘」欄位\n",
    "# --------------------------\n",
    "def convert_flight_time_to_minutes(time_str):\n",
    "    \"\"\"\n",
    "    將 'x 小時 y 分鐘' 格式的字串轉換為分鐘數\n",
    "    \"\"\"\n",
    "    if isinstance(time_str, str):\n",
    "        match = re.match(r'(\\d+)\\s*小時(?:\\s*(\\d+)\\s*分鐘)?', time_str)\n",
    "        if match:\n",
    "            hours = int(match.group(1))\n",
    "            minutes = int(match.group(2)) if match.group(2) else 0\n",
    "            return hours * 60 + minutes\n",
    "    return None\n",
    "\n",
    "data['飛行時間_分鐘'] = data['飛行時間'].apply(convert_flight_time_to_minutes)\n",
    "\n",
    "# 將「飛行時間_分鐘」移至「飛行時間」欄位之後\n",
    "cols = data.columns.tolist()\n",
    "if '飛行時間' in cols and '飛行時間_分鐘' in cols:\n",
    "    flight_idx = cols.index('飛行時間')\n",
    "    cols.insert(flight_idx + 1, cols.pop(cols.index('飛行時間_分鐘')))\n",
    "data = data[cols]\n",
    "\n",
    "# --------------------------\n",
    "# 9. 新增競爭航班數欄位\n",
    "# --------------------------\n",
    "# 此處依據「出發機場代號」、「抵達機場代號」、「出發日期」與「出發時段」來計算每一組別中航班的數量\n",
    "data['competing_flights'] = data.groupby(\n",
    "    ['出發機場代號', '抵達機場代號', '出發日期', '出發時段']\n",
    ")['航空公司'].transform('size')\n",
    "\n",
    "data = data.sort_values(\n",
    "    by=['出發機場代號', '抵達機場代號', '出發日期', '出發時段', '航空公司']\n",
    ")\n",
    "ㄋ\n",
    "# --------------------------\n",
    "# 10. 匯出處理後的資料\n",
    "# --------------------------\n",
    "output_path = '/Users/yuchingchen/Documents/專題/cleaned_data/short_flight_final.csv'\n",
    "data.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
